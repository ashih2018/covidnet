# -*- coding: utf-8 -*-
"""CovidNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EQWf-NQqb7-NTi3JSeuq05Go-b_BSBKQ

# Helper Code
"""

import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import numpy.random as npr
import scipy.misc
import torch
import torch.nn as nn

#########################################################################
# Paper https://www.overleaf.com/read/phxxyvtdcypm
#########################################################################

"""## Download Dataset"""

import zipfile
import os

#########################################################################
# Data from https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset
#########################################################################

if not os.path.exists("data.zip"):
    print("Downloading COVID-19 dataset")
    !wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=144mXrLIHEHQgxTiGjYcapT_AzBLUK9Z2' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=144mXrLIHEHQgxTiGjYcapT_AzBLUK9Z2" -O data.zip && rm -rf /tmp/cookies.txt

with zipfile.ZipFile('data.zip', 'r') as zip_ref:
    zip_ref.extractall('data')

import torchvision
import torchvision.transforms as transforms

def initialize_loader(train, validate, train_batch_size, val_batch_size):
    # Transform dimensions
    transform = transforms.Compose([
                                    transforms.Resize((224,224)),
                                    transforms.ToTensor(),
                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                                    ])
    covid_dataset = torchvision.datasets.ImageFolder('./data', transform=transform)
    n = len(covid_dataset)
    train_idx = int(train * n)
    val_idx = train_idx + int(validate * n)

    indices = np.arange(n)
    np.random.shuffle(indices)

    train_dataset = torch.utils.data.Subset(covid_dataset, indices[0:train_idx])
    val_dataset = torch.utils.data.Subset(covid_dataset, indices[train_idx:val_idx])
    test_dataset = torch.utils.data.Subset(covid_dataset, indices[val_idx:n])

    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=2)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True, num_workers=2)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True, num_workers=2)

    return train_loader, val_loader, test_loader

"""## Visualization"""

import cv2

def visualize_dataset(col):
    fig = plt.figure(figsize=(20, 8))

    i = 0
    for c in range(col):
        for r, cat in enumerate(["COVID", "non-COVID"]):
            image = os.listdir(os.path.join("data", cat))[i]
            path = os.path.join("data", cat, image)

            fig.add_subplot(2, col, (c + 1) + (r * col))
            plt.title(cat)
            plt.imshow(cv2.imread(path))
        i += 1

visualize_dataset(4)

"""# Training Code"""

eL
def plot_fig(data, title):
    plt.figure()
    plt.plot(data['iteration'], data['train'], label='Train')
    plt.plot(data['iteration'], data['validate'], label='Validation')
    plt.legend()
    plt.title(title)
    plt.xlabel("Epochs")

def train(args, model, dataloaders, criterion, optimizer):
    # Numpy random seed
    np.random.seed(args["seed"])
    losses = {"iteration": range(args["epochs"]), "train": [], "validate": []}
    accuracies = {"iteration": range(args["epochs"]), "train": [], "validate": []}
    if args["gpu"]:
        model.cuda()

    for epoch in range(args_dict["epochs"]):
        for phase in ["train", "validate"]:
            if phase == "train":
                model.train()
            else:
                model.eval()

            total_loss = 0.0
            total_correct = 0

            # Calculate FNR, FPR
            false_negatives = 0
            false_positives = 0
            num_covid = 0
            num_healthy = 0

            for i, (images, targets) in enumerate(dataloaders[phase]):
                if args_dict["gpu"]:
                    images = images.cuda()
                    targets = targets.cuda()

                # Zero the parameter gradients
                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == "train"):
                    # Forward pass
                    outputs = model(images)
                    loss = criterion(outputs, targets)
                    total_loss += loss.item() * images.size(0)
                    if phase == "train":
                        loss.backward()
                        optimizer.step()

                    pred, pred_masks = outputs.max(dim=1, keepdim=True)
                    total_correct += torch.sum(pred_masks.reshape(-1,) == targets).data.item()
                    
                    false_negatives += torch.sum(pred_masks.reshape(-1,) < targets).data.item()
                    false_positives += torch.sum(pred_masks.reshape(-1,) > targets).data.item()

                    num_covid += torch.sum(targets == 1).data.item()
                    num_healthy += torch.sum(targets == 0).data.item()

            epoch_loss = total_loss / len(dataloaders[phase].dataset)
            accuracy = total_correct / len(dataloaders[phase].dataset)
            if phase == "validate":
                print("Validation Loss: ", epoch_loss, " Validation Accuracy: ", accuracy)
            losses[phase].append(epoch_loss)
            accuracies[phase].append(accuracy)

    plot_fig(losses, "Loss")
    plot_fig(accuracies, "Accuracy")
    return model

def test_model(model, gpu, dataloader, criterion):
    model.eval()
    total_loss, total_correct = 0.0, 0
    
    # Calculate FNR, FPR
    false_negatives = 0
    false_positives = 0
    num_covid = 0
    num_healthy = 0
    for i, (images, targets) in enumerate(dataloader):
        if gpu:
            images = images.cuda()
            targets = targets.cuda()

        with torch.no_grad():
            output = model(images.float())
            pred, pred_masks = output.max(dim=1, keepdim=True)
            
            total_correct += torch.sum(pred_masks.reshape(-1,) == targets).data.item()
            total_loss += criterion(output, targets).data.item()
            
            false_negatives += torch.sum(pred_masks.reshape(-1,) < targets).data.item()
            false_positives += torch.sum(pred_masks.reshape(-1,) > targets).data.item()
            num_covid += torch.sum(targets == 1).data.item()
            num_healthy += torch.sum(targets == 0).data.item()
    
    if false_positives + num_healthy > 0:
      print("False positive rate: {}".format(false_positives / (false_positives + num_healthy)))
    else:
      print("False positive rate: N/A")

    if false_negatives + num_covid > 0:
      print("False negative rate: {}".format(false_negatives / (false_negatives + num_covid)))
    else:
      print("False negative rate: N/A")
    return total_correct / len(dataloader.dataset), total_loss

"""# Model: ResNet-18"""

import torchvision.models as models

# Set seeds for reproducibility
torch.manual_seed(18)
np.random.seed(18)

resnet18 = models.resnet18(pretrained=True)

# Repurpose Model
resnet18.requires_grad_(False)
resnet18.fc = nn.Sequential(
    nn.Linear(in_features=512, out_features=128, bias=True),
    nn.Linear(in_features=128, out_features=32, bias=True),
    nn.Linear(in_features=32, out_features=2, bias=True),
)

args_dict = {
    "seed": 413,
    "gpu": True,
    "epochs": 30,
    "learn_rate": 0.0001,
    "train_batch_size": 64,
    "val_batch_size": 64
}

train_loader, val_loader, test_loader = initialize_loader(0.7, 0.2, args_dict["train_batch_size"], args_dict["val_batch_size"])
dataloaders = {"train": train_loader, "validate": val_loader}

learned_parameters = []
for name, param in resnet18.named_parameters():
    if name.startswith("fc"):
        learned_parameters.append(param)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(learned_parameters, lr=args_dict["learn_rate"], weight_decay=1e-4)

torch.cuda.empty_cache()
CovidRN18 = train(args_dict, resnet18, dataloaders, criterion, optimizer)

"""## Test performance"""

test_acc, test_loss = test_model(CovidRN18, True, test_loader, criterion)
print("Test loss: ", test_loss, "Test accuracy: ", test_acc)

"""# Model: ResNet-50"""

import torchvision.models as models

# Set seeds for reproducibility
torch.manual_seed(50)
np.random.seed(50)

resnet50 = models.resnet50(pretrained=True)

# Repurpose Model
resnet50.requires_grad_(False)
resnet50.fc = nn.Sequential(
    nn.Linear(in_features=2048, out_features=1024, bias=True),
    nn.Linear(in_features=1024, out_features=2, bias=True)
)

args_dict = {
    "seed": 413,
    "gpu": True,
    "epochs": 30,
    "learn_rate": 0.001,
    "train_batch_size": 32,
    "val_batch_size": 32
}

train_loader, val_loader, test_loader = initialize_loader(0.7, 0.2, args_dict["train_batch_size"], args_dict["val_batch_size"])
dataloaders = {"train": train_loader, "validate": val_loader}

learned_parameters = []
for name, param in resnet50.named_parameters():
    if name.startswith("fc"):
        learned_parameters.append(param)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(learned_parameters, lr=args_dict["learn_rate"], weight_decay=1e-4)

torch.cuda.empty_cache()
CovidRN50 = train(args_dict, resnet50, dataloaders, criterion, optimizer)

"""## Test Performance"""

test_acc, test_loss = test_model(CovidRN50, True, test_loader, criterion)
print("Test loss: ", test_loss, "Test accuracy: ", test_acc)

"""# Model: Densenet-121"""

import torchvision.models as models

# Set seeds for reproducibility
torch.manual_seed(121)
np.random.seed(121)

densenet121 = models.densenet121(pretrained=True)

# Repurpose Model
densenet121.requires_grad_(True)
densenet121.classifier = nn.Linear(1024, 2)

args_dict = {
    "seed": 413,
    "gpu": True,
    "epochs": 20,
    "learn_rate": 0.001,
    "train_batch_size": 64,
    "val_batch_size": 64
}

train_loader, val_loader, test_loader = initialize_loader(0.7, 0.2, args_dict["train_batch_size"], args_dict["val_batch_size"])
dataloaders = {"train": train_loader, "validate": val_loader}

learned_parameters = []
for name, param in densenet121.named_parameters():
    if name.startswith("classifier"):
        learned_parameters.append(param)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(learned_parameters, lr=args_dict["learn_rate"], weight_decay=1e-4)

torch.cuda.empty_cache()
CovidDN121 = train(args_dict, densenet121, dataloaders, criterion, optimizer)

"""## Test Performance"""

test_acc, test_loss = test_model(CovidDN121, True, test_loader, criterion)
print("Test loss: ", test_loss, "Test accuracy: ", test_acc)

"""# Model: Densenet-161"""

import torchvision.models as models

# Set seeds for reproducibility
torch.manual_seed(161)
np.random.seed(161)

densenet161 = models.densenet161(pretrained=True)

# Repurpose Model
densenet161.requires_grad_(True)
densenet161.classifier = nn.Linear(2208, 2)

args_dict = {
    "seed": 413,
    "gpu": True,
    "epochs": 20,
    "learn_rate": 0.0001,
    "train_batch_size": 32,
    "val_batch_size": 32
}

train_loader, val_loader, test_loader = initialize_loader(0.7, 0.2, args_dict["train_batch_size"], args_dict["val_batch_size"])
dataloaders = {"train": train_loader, "validate": val_loader}

learned_parameters = []
for name, param in densenet161.named_parameters():
    if name.startswith("classifier"):
        learned_parameters.append(param)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(learned_parameters, lr=args_dict["learn_rate"], weight_decay=1e-4)

torch.cuda.empty_cache()
CovidDN161 = train(args_dict, densenet161, dataloaders, criterion, optimizer)

"""## Test Performance"""

test_acc, test_loss = test_model(CovidDN161, True, test_loader, criterion)
print("Test loss: ", test_loss, "Test accuracy: ", test_acc)

"""# Model Inception v3"""

import torchvision.models as models

# Set seeds for reproducibility
torch.manual_seed(3)
np.random.seed(3)

inception_v3 = models.inception_v3(pretrained=True, aux_logits=False)
inception_v3.Conv2d_1a_3x3 = nn.Sequential(
    nn.Upsample(size=299),
    inception_v3.Conv2d_1a_3x3
)

# Repurpose Model
inception_v3.requires_grad_(True)
inception_v3.fc = nn.Linear(2048, 2)

args_dict = {
    "seed": 413,
    "gpu": True,
    "epochs": 20,
    "learn_rate": 0.001,
    "train_batch_size": 32,
    "val_batch_size": 32
}

train_loader, val_loader, test_loader = initialize_loader(0.7, 0.2, args_dict["train_batch_size"], args_dict["val_batch_size"])
dataloaders = {"train": train_loader, "validate": val_loader}

learned_parameters = []
for name, param in inception_v3.named_parameters():
    if name.startswith("fc"):
        learned_parameters.append(param)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(learned_parameters, lr=args_dict["learn_rate"], weight_decay=1e-4)

torch.cuda.empty_cache()
Covidception = train(args_dict, inception_v3, dataloaders, criterion, optimizer)

test_acc, test_loss = test_model(Covidception, True, test_loader, criterion)
print("Test loss: ", test_loss, "Test accuracy: ", test_acc)

"""# Works Cited

https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html
"""